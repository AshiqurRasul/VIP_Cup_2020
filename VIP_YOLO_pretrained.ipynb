{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VIP_YOLO_pretrained.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2BWzvCMFQvE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "20c88128-0e3f-47d9-b1ae-9392d6ec9257"
      },
      "source": [
        "!git clone https://github.com/eriklindernoren/PyTorch-YOLOv3.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PyTorch-YOLOv3'...\n",
            "remote: Enumerating objects: 724, done.\u001b[K\n",
            "remote: Total 724 (delta 0), reused 0 (delta 0), pack-reused 724\u001b[K\n",
            "Receiving objects: 100% (724/724), 16.18 MiB | 22.44 MiB/s, done.\n",
            "Resolving deltas: 100% (411/411), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7GTYJSYGKPf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "24a2745f-e3f6-432a-ed2b-1319b84aa660"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/PyTorch-YOLOv3')\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "assets\tdata\t   LICENSE    README.md\t\ttest.py   utils\n",
            "config\tdetect.py  models.py  requirements.txt\ttrain.py  weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K19q1xIpHFSW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "68f7828d-39b2-4d20-8b77-688c5d7723ee"
      },
      "source": [
        "!bash download_weights.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-08 11:09:12--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M   192KB/s    in 24m 14s \n",
            "\n",
            "2020-07-08 11:33:27 (167 KB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n",
            "--2020-07-08 11:33:27--  https://pjreddie.com/media/files/yolov3-tiny.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35434956 (34M) [application/octet-stream]\n",
            "Saving to: ‘yolov3-tiny.weights’\n",
            "\n",
            "yolov3-tiny.weights 100%[===================>]  33.79M   125KB/s    in 4m 2s   \n",
            "\n",
            "2020-07-08 11:37:31 (143 KB/s) - ‘yolov3-tiny.weights’ saved [35434956/35434956]\n",
            "\n",
            "--2020-07-08 11:37:31--  https://pjreddie.com/media/files/darknet53.conv.74\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 162482580 (155M) [application/octet-stream]\n",
            "Saving to: ‘darknet53.conv.74’\n",
            "\n",
            "darknet53.conv.74   100%[===================>] 154.96M   147KB/s    in 17m 42s \n",
            "\n",
            "2020-07-08 11:55:14 (149 KB/s) - ‘darknet53.conv.74’ saved [162482580/162482580]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h83Bk-JTHxFH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "outputId": "7f59c872-b569-4394-eadf-124d000cfce3"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=1, checkpoint_model=None, class_path='data/coco.names', conf_thres=0.8, image_folder='data/samples', img_size=416, model_def='config/yolov3.cfg', n_cpu=0, nms_thres=0.4, weights_path='weights/yolov3.weights')\n",
            "\n",
            "Performing object detection:\n",
            "\t+ Batch 0, Inference Time: 0:00:01.508899\n",
            "\t+ Batch 1, Inference Time: 0:00:01.243603\n",
            "\t+ Batch 2, Inference Time: 0:00:01.242589\n",
            "\t+ Batch 3, Inference Time: 0:00:01.251698\n",
            "\t+ Batch 4, Inference Time: 0:00:01.239274\n",
            "\t+ Batch 5, Inference Time: 0:00:01.261578\n",
            "\t+ Batch 6, Inference Time: 0:00:01.263150\n",
            "\t+ Batch 7, Inference Time: 0:00:01.261760\n",
            "\t+ Batch 8, Inference Time: 0:00:01.255018\n",
            "\n",
            "Saving images:\n",
            "(0) Image: 'data/samples/dog.jpg'\n",
            "\t+ Label: dog, Conf: 0.99335\n",
            "\t+ Label: bicycle, Conf: 0.99981\n",
            "\t+ Label: truck, Conf: 0.94229\n",
            "(1) Image: 'data/samples/eagle.jpg'\n",
            "\t+ Label: bird, Conf: 0.99703\n",
            "(2) Image: 'data/samples/field.jpg'\n",
            "\t+ Label: person, Conf: 0.99996\n",
            "\t+ Label: horse, Conf: 0.99977\n",
            "\t+ Label: dog, Conf: 0.99409\n",
            "(3) Image: 'data/samples/giraffe.jpg'\n",
            "\t+ Label: giraffe, Conf: 0.99959\n",
            "\t+ Label: zebra, Conf: 0.97958\n",
            "(4) Image: 'data/samples/herd_of_horses.jpg'\n",
            "\t+ Label: horse, Conf: 0.99459\n",
            "\t+ Label: horse, Conf: 0.99352\n",
            "\t+ Label: horse, Conf: 0.96845\n",
            "\t+ Label: horse, Conf: 0.99478\n",
            "(5) Image: 'data/samples/messi.jpg'\n",
            "\t+ Label: person, Conf: 0.99993\n",
            "\t+ Label: person, Conf: 0.99984\n",
            "\t+ Label: person, Conf: 0.99996\n",
            "(6) Image: 'data/samples/person.jpg'\n",
            "\t+ Label: person, Conf: 0.99883\n",
            "\t+ Label: dog, Conf: 0.99275\n",
            "(7) Image: 'data/samples/room.jpg'\n",
            "\t+ Label: chair, Conf: 0.99906\n",
            "\t+ Label: chair, Conf: 0.96942\n",
            "\t+ Label: clock, Conf: 0.99971\n",
            "(8) Image: 'data/samples/street.jpg'\n",
            "\t+ Label: car, Conf: 0.99977\n",
            "\t+ Label: car, Conf: 0.99402\n",
            "\t+ Label: car, Conf: 0.99841\n",
            "\t+ Label: car, Conf: 0.99785\n",
            "\t+ Label: car, Conf: 0.97907\n",
            "\t+ Label: car, Conf: 0.95370\n",
            "\t+ Label: traffic light, Conf: 0.99995\n",
            "\t+ Label: car, Conf: 0.62254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO0vbyrZS6zO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1671ee93-13c1-4aad-a570-4fa9e205719c"
      },
      "source": [
        "os.chdir('/content/PyTorch-YOLOv3')\n",
        "!python3 detect.py --image_folder data/samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=1, checkpoint_model=None, class_path='data/coco.names', conf_thres=0.8, image_folder='data/samples', img_size=416, model_def='config/yolov3.cfg', n_cpu=0, nms_thres=0.4, weights_path='weights/yolov3.weights')\n",
            "\n",
            "Performing object detection:\n",
            "\t+ Batch 0, Inference Time: 0:00:01.378347\n",
            "\t+ Batch 1, Inference Time: 0:00:01.262959\n",
            "\t+ Batch 2, Inference Time: 0:00:01.298546\n",
            "\t+ Batch 3, Inference Time: 0:00:01.266500\n",
            "\t+ Batch 4, Inference Time: 0:00:01.282984\n",
            "\t+ Batch 5, Inference Time: 0:00:01.266682\n",
            "\t+ Batch 6, Inference Time: 0:00:01.265547\n",
            "\t+ Batch 7, Inference Time: 0:00:01.253877\n",
            "\t+ Batch 8, Inference Time: 0:00:01.259687\n",
            "\t+ Batch 9, Inference Time: 0:00:01.271621\n",
            "\t+ Batch 10, Inference Time: 0:00:01.271359\n",
            "\t+ Batch 11, Inference Time: 0:00:01.266224\n",
            "\t+ Batch 12, Inference Time: 0:00:01.253184\n",
            "\t+ Batch 13, Inference Time: 0:00:01.265973\n",
            "\t+ Batch 14, Inference Time: 0:00:01.260402\n",
            "\t+ Batch 15, Inference Time: 0:00:01.278113\n",
            "\t+ Batch 16, Inference Time: 0:00:01.280756\n",
            "\t+ Batch 17, Inference Time: 0:00:01.288383\n",
            "\t+ Batch 18, Inference Time: 0:00:01.292130\n",
            "\t+ Batch 19, Inference Time: 0:00:01.287761\n",
            "\t+ Batch 20, Inference Time: 0:00:01.275745\n",
            "\t+ Batch 21, Inference Time: 0:00:01.288353\n",
            "\t+ Batch 22, Inference Time: 0:00:01.272361\n",
            "\t+ Batch 23, Inference Time: 0:00:01.279910\n",
            "\t+ Batch 24, Inference Time: 0:00:01.275453\n",
            "\t+ Batch 25, Inference Time: 0:00:01.294548\n",
            "\t+ Batch 26, Inference Time: 0:00:01.293945\n",
            "\t+ Batch 27, Inference Time: 0:00:01.254685\n",
            "\t+ Batch 28, Inference Time: 0:00:01.267045\n",
            "\t+ Batch 29, Inference Time: 0:00:01.265152\n",
            "\t+ Batch 30, Inference Time: 0:00:01.270813\n",
            "\t+ Batch 31, Inference Time: 0:00:01.252879\n",
            "\t+ Batch 32, Inference Time: 0:00:01.256597\n",
            "\t+ Batch 33, Inference Time: 0:00:01.275185\n",
            "\t+ Batch 34, Inference Time: 0:00:01.270106\n",
            "\t+ Batch 35, Inference Time: 0:00:01.267715\n",
            "\t+ Batch 36, Inference Time: 0:00:01.264996\n",
            "\t+ Batch 37, Inference Time: 0:00:01.255100\n",
            "\t+ Batch 38, Inference Time: 0:00:01.251833\n",
            "\t+ Batch 39, Inference Time: 0:00:01.271368\n",
            "\t+ Batch 40, Inference Time: 0:00:01.251212\n",
            "\t+ Batch 41, Inference Time: 0:00:01.273491\n",
            "\t+ Batch 42, Inference Time: 0:00:01.248944\n",
            "\t+ Batch 43, Inference Time: 0:00:01.274765\n",
            "\t+ Batch 44, Inference Time: 0:00:01.262647\n",
            "\t+ Batch 45, Inference Time: 0:00:01.270824\n",
            "\t+ Batch 46, Inference Time: 0:00:01.252762\n",
            "\t+ Batch 47, Inference Time: 0:00:01.254658\n",
            "\t+ Batch 48, Inference Time: 0:00:01.247322\n",
            "\t+ Batch 49, Inference Time: 0:00:01.282661\n",
            "\t+ Batch 50, Inference Time: 0:00:01.258785\n",
            "\t+ Batch 51, Inference Time: 0:00:01.278208\n",
            "\t+ Batch 52, Inference Time: 0:00:01.256613\n",
            "\t+ Batch 53, Inference Time: 0:00:01.262537\n",
            "\t+ Batch 54, Inference Time: 0:00:01.265409\n",
            "\t+ Batch 55, Inference Time: 0:00:01.259100\n",
            "\t+ Batch 56, Inference Time: 0:00:01.263865\n",
            "\t+ Batch 57, Inference Time: 0:00:01.263985\n",
            "\t+ Batch 58, Inference Time: 0:00:01.274461\n",
            "\t+ Batch 59, Inference Time: 0:00:01.305908\n",
            "\t+ Batch 60, Inference Time: 0:00:01.273116\n",
            "\t+ Batch 61, Inference Time: 0:00:01.291601\n",
            "\t+ Batch 62, Inference Time: 0:00:01.268787\n",
            "\t+ Batch 63, Inference Time: 0:00:01.290077\n",
            "\t+ Batch 64, Inference Time: 0:00:01.275868\n",
            "\t+ Batch 65, Inference Time: 0:00:01.284638\n",
            "\t+ Batch 66, Inference Time: 0:00:01.286389\n",
            "\t+ Batch 67, Inference Time: 0:00:01.291705\n",
            "\t+ Batch 68, Inference Time: 0:00:01.290523\n",
            "\t+ Batch 69, Inference Time: 0:00:01.271493\n",
            "\t+ Batch 70, Inference Time: 0:00:01.280300\n",
            "\t+ Batch 71, Inference Time: 0:00:01.303446\n",
            "\t+ Batch 72, Inference Time: 0:00:01.303591\n",
            "\t+ Batch 73, Inference Time: 0:00:01.292261\n",
            "\t+ Batch 74, Inference Time: 0:00:01.272694\n",
            "\t+ Batch 75, Inference Time: 0:00:01.284529\n",
            "\t+ Batch 76, Inference Time: 0:00:01.305196\n",
            "\t+ Batch 77, Inference Time: 0:00:01.280263\n",
            "\t+ Batch 78, Inference Time: 0:00:01.275524\n",
            "\t+ Batch 79, Inference Time: 0:00:01.256860\n",
            "\t+ Batch 80, Inference Time: 0:00:01.272393\n",
            "\t+ Batch 81, Inference Time: 0:00:01.259931\n",
            "\t+ Batch 82, Inference Time: 0:00:01.256204\n",
            "\t+ Batch 83, Inference Time: 0:00:01.256488\n",
            "\t+ Batch 84, Inference Time: 0:00:01.276770\n",
            "\t+ Batch 85, Inference Time: 0:00:01.260829\n",
            "\t+ Batch 86, Inference Time: 0:00:01.246338\n",
            "\t+ Batch 87, Inference Time: 0:00:01.250720\n",
            "\t+ Batch 88, Inference Time: 0:00:01.263207\n",
            "\t+ Batch 89, Inference Time: 0:00:01.252959\n",
            "\t+ Batch 90, Inference Time: 0:00:01.257065\n",
            "\t+ Batch 91, Inference Time: 0:00:01.259540\n",
            "\t+ Batch 92, Inference Time: 0:00:01.299732\n",
            "\t+ Batch 93, Inference Time: 0:00:01.248180\n",
            "\t+ Batch 94, Inference Time: 0:00:01.251334\n",
            "\t+ Batch 95, Inference Time: 0:00:01.254809\n",
            "\t+ Batch 96, Inference Time: 0:00:01.268497\n",
            "\n",
            "Saving images:\n",
            "(0) Image: 'data/samples/01_fisheye_day_000058.jpg'\n",
            "\t+ Label: car, Conf: 0.99821\n",
            "\t+ Label: car, Conf: 0.98526\n",
            "\t+ Label: car, Conf: 0.99813\n",
            "(1) Image: 'data/samples/01_fisheye_day_000244.jpg'\n",
            "\t+ Label: car, Conf: 0.99833\n",
            "\t+ Label: car, Conf: 0.99855\n",
            "\t+ Label: car, Conf: 0.99892\n",
            "(2) Image: 'data/samples/01_fisheye_day_000506.jpg'\n",
            "\t+ Label: car, Conf: 0.98859\n",
            "\t+ Label: car, Conf: 0.96258\n",
            "\t+ Label: car, Conf: 0.99780\n",
            "\t+ Label: car, Conf: 0.99802\n",
            "\t+ Label: car, Conf: 0.99739\n",
            "(3) Image: 'data/samples/02_fisheye_day_000687.jpg'\n",
            "\t+ Label: car, Conf: 0.99706\n",
            "\t+ Label: car, Conf: 0.99691\n",
            "\t+ Label: car, Conf: 0.99709\n",
            "(4) Image: 'data/samples/03_fisheye_day_000172.jpg'\n",
            "\t+ Label: car, Conf: 0.93683\n",
            "(5) Image: 'data/samples/03_fisheye_day_000363.jpg'\n",
            "\t+ Label: car, Conf: 0.94780\n",
            "(6) Image: 'data/samples/04_fisheye_day_000204.jpg'\n",
            "\t+ Label: person, Conf: 0.97715\n",
            "(7) Image: 'data/samples/04_fisheye_day_000332.jpg'\n",
            "(8) Image: 'data/samples/04_fisheye_day_000430.jpg'\n",
            "(9) Image: 'data/samples/04_fisheye_day_000495.jpg'\n",
            "\t+ Label: car, Conf: 0.99658\n",
            "\t+ Label: car, Conf: 0.89802\n",
            "\t+ Label: car, Conf: 0.88905\n",
            "(10) Image: 'data/samples/04_fisheye_day_000795.jpg'\n",
            "\t+ Label: car, Conf: 0.99830\n",
            "\t+ Label: truck, Conf: 0.77995\n",
            "(11) Image: 'data/samples/04_fisheye_day_000826.jpg'\n",
            "\t+ Label: car, Conf: 0.99819\n",
            "\t+ Label: car, Conf: 0.99938\n",
            "(12) Image: 'data/samples/04_fisheye_day_000924.jpg'\n",
            "\t+ Label: car, Conf: 0.99844\n",
            "\t+ Label: car, Conf: 0.99954\n",
            "(13) Image: 'data/samples/04_fisheye_day_001137.jpg'\n",
            "\t+ Label: car, Conf: 0.97849\n",
            "\t+ Label: car, Conf: 0.99344\n",
            "(14) Image: 'data/samples/04_fisheye_day_001320.jpg'\n",
            "(15) Image: 'data/samples/05_fisheye_day_000117.jpg'\n",
            "\t+ Label: car, Conf: 0.94044\n",
            "(16) Image: 'data/samples/05_fisheye_day_000127.jpg'\n",
            "\t+ Label: car, Conf: 0.92660\n",
            "(17) Image: 'data/samples/05_fisheye_day_000198.jpg'\n",
            "\t+ Label: car, Conf: 0.95351\n",
            "(18) Image: 'data/samples/05_fisheye_day_000207.jpg'\n",
            "(19) Image: 'data/samples/05_fisheye_day_000308.jpg'\n",
            "detect.py:103: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig, ax = plt.subplots(1)\n",
            "\t+ Label: car, Conf: 0.99064\n",
            "\t+ Label: car, Conf: 0.97772\n",
            "\t+ Label: car, Conf: 0.98782\n",
            "(20) Image: 'data/samples/05_fisheye_day_000320.jpg'\n",
            "detect.py:102: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  plt.figure()\n",
            "\t+ Label: car, Conf: 0.95331\n",
            "\t+ Label: car, Conf: 0.95323\n",
            "(21) Image: 'data/samples/05_fisheye_day_000341.jpg'\n",
            "\t+ Label: car, Conf: 0.93656\n",
            "(22) Image: 'data/samples/05_fisheye_day_000360.jpg'\n",
            "\t+ Label: car, Conf: 0.98145\n",
            "(23) Image: 'data/samples/05_fisheye_day_000376.jpg'\n",
            "\t+ Label: car, Conf: 0.98798\n",
            "(24) Image: 'data/samples/05_fisheye_day_000424.jpg'\n",
            "\t+ Label: car, Conf: 0.99087\n",
            "\t+ Label: car, Conf: 0.93157\n",
            "(25) Image: 'data/samples/05_fisheye_day_000446.jpg'\n",
            "\t+ Label: car, Conf: 0.98141\n",
            "(26) Image: 'data/samples/05_fisheye_day_000484.jpg'\n",
            "\t+ Label: car, Conf: 0.95751\n",
            "(27) Image: 'data/samples/akbelen_1_000379.jpg'\n",
            "(28) Image: 'data/samples/akbelen_5_000146.jpg'\n",
            "\t+ Label: train, Conf: 0.93252\n",
            "(29) Image: 'data/samples/babil_1_000061.jpg'\n",
            "(30) Image: 'data/samples/babil_1_000248.jpg'\n",
            "(31) Image: 'data/samples/babil_1_000385.jpg'\n",
            "(32) Image: 'data/samples/babil_1_000480.jpg'\n",
            "(33) Image: 'data/samples/babil_1_000710.jpg'\n",
            "(34) Image: 'data/samples/babil_1_000936.jpg'\n",
            "(35) Image: 'data/samples/babil_3_000075.jpg'\n",
            "\t+ Label: car, Conf: 0.90860\n",
            "(36) Image: 'data/samples/babil_3_000944.jpg'\n",
            "(37) Image: 'data/samples/babil_5_000372.jpg'\n",
            "(38) Image: 'data/samples/babil_5_000523.jpg'\n",
            "(39) Image: 'data/samples/babil_5_000634.jpg'\n",
            "\t+ Label: car, Conf: 0.98670\n",
            "(40) Image: 'data/samples/babil_5_000938.jpg'\n",
            "(41) Image: 'data/samples/babil_5_000984.jpg'\n",
            "(42) Image: 'data/samples/babil_7_000207.jpg'\n",
            "\t+ Label: car, Conf: 0.97403\n",
            "(43) Image: 'data/samples/babil_7_000292.jpg'\n",
            "\t+ Label: car, Conf: 0.97991\n",
            "(44) Image: 'data/samples/babil_7_000364.jpg'\n",
            "\t+ Label: car, Conf: 0.95262\n",
            "(45) Image: 'data/samples/babil_7_000378.jpg'\n",
            "\t+ Label: car, Conf: 0.95492\n",
            "(46) Image: 'data/samples/babil_7_000424.jpg'\n",
            "\t+ Label: car, Conf: 0.95446\n",
            "\t+ Label: car, Conf: 0.98286\n",
            "(47) Image: 'data/samples/babil_7_000600.jpg'\n",
            "\t+ Label: clock, Conf: 0.31022\n",
            "(48) Image: 'data/samples/babil_7_000616.jpg'\n",
            "\t+ Label: car, Conf: 0.99667\n",
            "\t+ Label: clock, Conf: 0.26214\n",
            "(49) Image: 'data/samples/babil_7_000709.jpg'\n",
            "(50) Image: 'data/samples/babil_7_000850.jpg'\n",
            "\t+ Label: clock, Conf: 0.57385\n",
            "(51) Image: 'data/samples/babil_9_000039.jpg'\n",
            "(52) Image: 'data/samples/babil_9_000060.jpg'\n",
            "(53) Image: 'data/samples/babil_9_000084.jpg'\n",
            "(54) Image: 'data/samples/babil_9_000160.jpg'\n",
            "(55) Image: 'data/samples/babil_9_000175.jpg'\n",
            "(56) Image: 'data/samples/babil_9_000619.jpg'\n",
            "(57) Image: 'data/samples/babil_9_000696.jpg'\n",
            "\t+ Label: car, Conf: 0.71750\n",
            "\t+ Label: car, Conf: 0.62444\n",
            "(58) Image: 'data/samples/frame_cnr_1_000044.jpg'\n",
            "\t+ Label: car, Conf: 0.96390\n",
            "(59) Image: 'data/samples/frame_cnr_1_000048.jpg'\n",
            "\t+ Label: car, Conf: 0.96219\n",
            "(60) Image: 'data/samples/frame_cnr_1_000248.jpg'\n",
            "\t+ Label: car, Conf: 0.96763\n",
            "(61) Image: 'data/samples/frame_cnr_1_000363.jpg'\n",
            "\t+ Label: car, Conf: 0.98583\n",
            "\t+ Label: car, Conf: 0.99497\n",
            "\t+ Label: truck, Conf: 0.71634\n",
            "(62) Image: 'data/samples/frame_cnr_1_000635.jpg'\n",
            "\t+ Label: car, Conf: 0.96114\n",
            "(63) Image: 'data/samples/frame_cnr_1_001085.jpg'\n",
            "\t+ Label: car, Conf: 0.98487\n",
            "(64) Image: 'data/samples/frame_cnr_1_001121.jpg'\n",
            "\t+ Label: car, Conf: 0.97372\n",
            "(65) Image: 'data/samples/frame_cnr_1_001130.jpg'\n",
            "\t+ Label: car, Conf: 0.97246\n",
            "\t+ Label: car, Conf: 0.98048\n",
            "(66) Image: 'data/samples/frame_cnr_1_001246.jpg'\n",
            "\t+ Label: car, Conf: 0.98723\n",
            "\t+ Label: car, Conf: 0.77314\n",
            "(67) Image: 'data/samples/frame_cnr_6_000167.jpg'\n",
            "\t+ Label: car, Conf: 0.96706\n",
            "(68) Image: 'data/samples/frame_cnr_6_000333.jpg'\n",
            "\t+ Label: car, Conf: 0.94326\n",
            "\t+ Label: car, Conf: 0.95269\n",
            "(69) Image: 'data/samples/frame_cnr_6_000456.jpg'\n",
            "\t+ Label: car, Conf: 0.96419\n",
            "\t+ Label: car, Conf: 0.84726\n",
            "(70) Image: 'data/samples/frame_cnr_6_000489.jpg'\n",
            "\t+ Label: car, Conf: 0.93635\n",
            "(71) Image: 'data/samples/frame_cnr_6_000516.jpg'\n",
            "\t+ Label: car, Conf: 0.96317\n",
            "(72) Image: 'data/samples/frame_cnr_6_000821.jpg'\n",
            "\t+ Label: car, Conf: 0.97824\n",
            "(73) Image: 'data/samples/gedizler_1_000092.jpg'\n",
            "\t+ Label: car, Conf: 0.99506\n",
            "\t+ Label: clock, Conf: 0.46098\n",
            "\t+ Label: train, Conf: 0.39312\n",
            "(74) Image: 'data/samples/gedizler_1_000441.jpg'\n",
            "\t+ Label: car, Conf: 0.99694\n",
            "\t+ Label: clock, Conf: 0.47878\n",
            "(75) Image: 'data/samples/gedizler_1_000752.jpg'\n",
            "\t+ Label: car, Conf: 0.85700\n",
            "(76) Image: 'data/samples/gedizler_1_000916.jpg'\n",
            "\t+ Label: car, Conf: 0.94623\n",
            "\t+ Label: clock, Conf: 0.65971\n",
            "(77) Image: 'data/samples/gedizler_3_000236.jpg'\n",
            "\t+ Label: clock, Conf: 0.81681\n",
            "(78) Image: 'data/samples/gedizler_3_000349.jpg'\n",
            "\t+ Label: car, Conf: 0.87578\n",
            "\t+ Label: clock, Conf: 0.78156\n",
            "(79) Image: 'data/samples/gedizler_3_000646.jpg'\n",
            "\t+ Label: clock, Conf: 0.57009\n",
            "(80) Image: 'data/samples/rifatuslu_2_000072.jpg'\n",
            "\t+ Label: car, Conf: 0.98823\n",
            "(81) Image: 'data/samples/rifatuslu_2_000081.jpg'\n",
            "\t+ Label: car, Conf: 0.99868\n",
            "(82) Image: 'data/samples/rifatuslu_2_000386.jpg'\n",
            "(83) Image: 'data/samples/rifatuslu_2_000440.jpg'\n",
            "(84) Image: 'data/samples/rifatuslu_2_000568.jpg'\n",
            "(85) Image: 'data/samples/rifatuslu_4_000308.jpg'\n",
            "(86) Image: 'data/samples/rifatuslu_4_000504.jpg'\n",
            "(87) Image: 'data/samples/rifatuslu_4_000549.jpg'\n",
            "(88) Image: 'data/samples/rifatuslu_4_000730.jpg'\n",
            "(89) Image: 'data/samples/rifatuslu_4_000962.jpg'\n",
            "(90) Image: 'data/samples/rifatuslu_6_000169.jpg'\n",
            "\t+ Label: car, Conf: 0.99379\n",
            "(91) Image: 'data/samples/rifatuslu_6_000403.jpg'\n",
            "\t+ Label: car, Conf: 0.99769\n",
            "\t+ Label: car, Conf: 0.99208\n",
            "\t+ Label: suitcase, Conf: 0.24471\n",
            "(92) Image: 'data/samples/rifatuslu_6_000522.jpg'\n",
            "\t+ Label: car, Conf: 0.98564\n",
            "\t+ Label: suitcase, Conf: 0.18836\n",
            "(93) Image: 'data/samples/rifatuslu_6_000599.jpg'\n",
            "(94) Image: 'data/samples/rifatuslu_6_000805.jpg'\n",
            "(95) Image: 'data/samples/rifatuslu_6_000876.jpg'\n",
            "(96) Image: 'data/samples/rifatuslu_6_000883.jpg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWCFAe2PT8cT"
      },
      "source": [
        "import numpy as np\n",
        "x = np.random.rand(100)*1000\n",
        "x = np.ceil(x).astype(int)\n",
        "os.chdir('/content/drive/My Drive/VIP CUP dataset/fisheye-day-30062020/images/train/')\n",
        "l = os.listdir('/content/drive/My Drive/VIP CUP dataset/fisheye-day-30062020/images/train/')\n",
        "\n",
        "import shutil\n",
        "for i in x:\n",
        "    source_path = '/content/drive/My Drive/VIP CUP dataset/fisheye-day-30062020/images/train/' + l[i]\n",
        "    dest_path = '/content/PyTorch-YOLOv3/data/samples/' + l[i]\n",
        "    shutil.copyfile(source_path, dest_path)\n",
        "    if os.path.isfile(source_path) and os.path.isfile(dest_path):\n",
        "        print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6dyPm15YK7D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "276c09e9-d13f-49e0-ad81-1820ab073962"
      },
      "source": [
        "!zip -r /content/output_images.zip /content/PyTorch-YOLOv3/output\n",
        "from google.colab import files\n",
        "files.download('/content/output_images.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/PyTorch-YOLOv3/output/ (stored 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/frame_cnr_1_000048.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_6_000403.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/frame_cnr_1_000248.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_1_000480.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/05_fisheye_day_000360.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_6_000805.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_3_000075.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_7_000616.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/05_fisheye_day_000341.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_7_000850.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/frame_cnr_1_001246.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_9_000060.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/04_fisheye_day_000924.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/gedizler_3_000236.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_9_000160.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_6_000883.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/05_fisheye_day_000424.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_9_000619.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_9_000696.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/02_fisheye_day_000687.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/04_fisheye_day_000332.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_6_000599.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/frame_cnr_1_001121.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/05_fisheye_day_000446.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/04_fisheye_day_000795.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/04_fisheye_day_001320.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/04_fisheye_day_001137.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_1_000248.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_5_000984.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_2_000386.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_4_000504.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/01_fisheye_day_000244.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_9_000039.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/akbelen_1_000379.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/frame_cnr_6_000516.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/04_fisheye_day_000495.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_1_000710.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_6_000522.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/akbelen_5_000146.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/gedizler_1_000092.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/05_fisheye_day_000308.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/frame_cnr_6_000333.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/05_fisheye_day_000376.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_2_000072.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_6_000876.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/frame_cnr_1_001130.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/05_fisheye_day_000127.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/gedizler_3_000349.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/frame_cnr_6_000821.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/05_fisheye_day_000484.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_5_000938.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_2_000081.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/frame_cnr_1_000635.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/gedizler_1_000916.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/04_fisheye_day_000204.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_9_000175.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_1_000385.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/frame_cnr_1_000363.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/05_fisheye_day_000117.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/01_fisheye_day_000058.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/frame_cnr_1_000044.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_7_000424.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/05_fisheye_day_000207.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_6_000169.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_1_000936.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/gedizler_1_000752.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_2_000440.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_1_000061.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_7_000709.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_5_000523.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_9_000084.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/04_fisheye_day_000826.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_7_000378.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/03_fisheye_day_000172.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/05_fisheye_day_000198.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_7_000292.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_7_000364.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_4_000308.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_7_000207.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/gedizler_3_000646.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/04_fisheye_day_000430.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_4_000730.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/frame_cnr_1_001085.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/01_fisheye_day_000506.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_3_000944.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/03_fisheye_day_000363.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/frame_cnr_6_000456.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/05_fisheye_day_000320.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_5_000634.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_5_000372.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_4_000962.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/babil_7_000600.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/frame_cnr_6_000489.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_2_000568.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/rifatuslu_4_000549.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/frame_cnr_6_000167.png (deflated 0%)\n",
            "  adding: content/PyTorch-YOLOv3/output/gedizler_1_000441.png (deflated 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f3f86473-9deb-46d2-9f1f-b9527a2bf496\", \"output_images.zip\", 20116589)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}